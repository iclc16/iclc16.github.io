for(i in 1:length(mt)) {
if(length(mt[[i]])<mtMax) {
mt[[i]][((length(mt[[i]]))+1):(mtMax)] <- NA
}
}
# transform to df
kwic <- as.data.frame(matrix(ncol=mtMax, nrow=length(mt)),
stringsAsFactors = F)
for(i in 1:nrow(kwic)) {
kwic[i,] <- mt[[i]]
}
# add colnames
colnames(kwic) <- paste("Metatag", 1:mtMax, sep="")
# transform %%%COMMA%%% in URLs back to real commas
kwic$Metatag1 <- gsub("%%%COMMA%%%", "", kwic$Metatag1)
# add left, right, key
kwic$Left <- lc
kwic$Key <- key
kwic$Right <- rc
} else {
kwic <- data.frame(Left  = lc,
Key   = key,
Right = rc)
}
} else {
kwic <- data.frame(Left  = lc,
Key   = key,
Right = rc)
}
# create _with_anno column
kwic$Key_with_anno   <- kwic$Key
# function for getting annotations
# (the lookaround assertions make sure that slashes
# that belong to the original text are NOT replaced)
get_anno <- function(myTx) {
w <- .splitter(trimws(gsub("[[:space:]]+/(?![[:space:]])", "/", myTx, perl = T)), " ")
w <- w[which(w!="")] # remove empty vector elements
w <- lapply(1:length(w), function(i) .splitter(w[i], "(?<!^)/", perl = T))
return(w)
}
# how many annotation tags?
w <- get_anno(kwic$Key[1])
la <- max(sapply(1:length(w), function(i) length(w[[i]])))
paste_anno <- function(myTx, k) {
w <- get_anno(myTx)
w <- paste0(sapply(1:length(w), function(i) w[[i]][k]), collapse = " ")
return(w)
}
# add columns
l <- length(kwic)
kwic[, (l+1):(l+la)] <- NA
colnames(kwic)[(l+1):(l+la)] <- paste0("Tag", 1:la, "_Key", sep = "")
# status update
if(verbose) {
cat("Processing tags in the keyword column ... \n")
}
# fill columns
for(j in 1:la) {
kwic[, l+j] <- sapply(1:nrow(kwic), function(i) paste_anno(kwic$Key[i], j))
}
# strip tags from Key column
kwic$Key <- kwic$Tag1_Key
View(kwic)
# create _with_anno columns
kwic$Left_with_anno  <- kwic$Left
kwic$Right_with_anno <- kwic$Right
# how many annotation tags?
w <- get_anno(kwic$Left[1])
la <- max(sapply(1:length(w), function(i) length(w[[i]])))
# add columns: left
l <- length(kwic)
kwic[, (l+1):(l+la)] <- NA
colnames(kwic)[(l+1):(l+la)] <- paste0("Tag", 1:la, "_Left", sep = "")
# fill columns: left
for(j in 1:(la)) {
kwic[, l+j] <- sapply(1:nrow(kwic), function(i) paste_anno(kwic$Left[i], j))
}
# strip tags from Left column
kwic$Left <- kwic$Tag1_Left
View(kwic)
View(kwic)
# add columns: right
l <- length(kwic)
kwic[, (l+1):(l+la)] <- NA
colnames(kwic)[(l+1):(l+la)] <- paste0("Tag", 1:la, "_Right", sep = "")
# fill columns: right
for(j in 1:la) {
kwic[, l+j] <- sapply(1:nrow(kwic), function(i) paste_anno(kwic$Right[i], j))
}
# strip tags from Left column
kwic$Right <- kwic$Tag2_Right
# reorder columns
lf  <- grep("Tag.*_Left", colnames(kwic))
ky  <- grep("Tag.*_Key", colnames(kwic))
rgt <- grep("Tag.*_Right", colnames(kwic))
lwa <- which(colnames(kwic)=="Left_with_anno")
rwa <- which(colnames(kwic)=="Right_with_anno")
kwa <- which(colnames(kwic)=="Key_with_anno")
kwic <- kwic[,c(1:(min(c(lf, ky, rgt, lwa, rwa, kwa))-1), lwa, kwa, rwa, lf, ky, rgt)]
View(kwic)
64-24
40/326
71.60+49
120.6+108
1320+340+360
554 * 1.5
831*10
655.39*10
655.39*1.5
983.085*10
655.39*2.5
1638*10
1638*7
1638*5
1638*5
553.94*2.5
1384.85*10
1384.85*7
1384.85*5
74100*3
222300*0.65
7935.95*2
15871.9*3
80100+74100+15871.9+85196
80100+74100+15871.9
80100+74100+15871.9
240300+144495+48615.7
170071.90*3
80100*3
74100*3
74100*0.65
48165*3
80100+48165+15871.9
144136.9*3
240300+144495+47615
240300+144495+47615.7
170071.9*3
144136.9*3
80100*3
48165*3
15871.9*3
240300+144495+47615.7
234*2
300+470
320/5
320/4
460+640+400
432410.7+6000+3000+15000
library(concordances)
citation("concordances")
6100*60
library(tidyverse)
library(googlesheets4)
gs4_deauth()
read_sheet("https://docs.google.com/spreadsheets/d/1zKoKMFtRHufZuio941yIMOw2EdHYOTzrR20hFq4ZlXQ/edit?usp=sharing", sheet = "Sheet1")
# read sheet
d <- read_sheet("https://docs.google.com/spreadsheets/d/1zKoKMFtRHufZuio941yIMOw2EdHYOTzrR20hFq4ZlXQ/edit?usp=sharing", sheet = "Sheet1")
# pivot to longer
d
?pivot_longer
# pivot to longer
d %>% pivot_longer(cols = c(2:8))
# pivot to longer
d %>% pivot_longer(cols = c(3:8))
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = `Wortstellung im Original`)) +
geom_col()
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Wortstellung)) +
geom_col()
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n"))
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, fill = Kategorie, group = Wortstellung)) +
geom_col()
?geom_col
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Kategorie)) +
geom_col() + facet_grid(~ Wortstellung)
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Kategorie)) +
geom_col(position = position_dodge()) + facet_grid(~ Wortstellung)
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Kategorie, fill = Kategorie)) +
geom_col(position = position_dodge()) + facet_grid(~ Wortstellung)
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Kategorie, fill = Kategorie)) +
geom_col(position = position_dodge()) + facet_grid(~ Wortstellung) +
theme(axis.text.x = element_text(angle=45, hjust=.9, size=12))
# pivot to longer
d %>% pivot_longer(cols = c(3:8)) %>% setNames(c("Beispielsatz", "Wortstellung", "Kategorie", "n")) %>%
ggplot(aes(x = Beispielsatz, y = n, group = Kategorie, fill = Kategorie)) +
geom_col(position = position_dodge()) + facet_grid(~ Wortstellung)
library(rethinking)
data("UCBadmit")
d <- UCBadmit
d$gid <- ifelse ( d$applicant.gender == "male", 1L, 2L)
dat <- list(A = d$admit, N = d$applications, gid = d$gid)
m12.1 <- ulam(
alist(
A ~ dbetabinom(N, pbar, theta),
logit(pbar) <- a[gid],
a[gid] <- dnorm(0, 1.5),
transpars> theta <<- phi + 2.0,
phi ~ dexp(1)
),
data = dat, chains = 4
)
pbar <- 0.5
theta <- 5
m12.1 <- ulam(
alist(
A ~ dbetabinom(N, pbar, theta),
logit(pbar) <- a[gid],
a[gid] <- dnorm(0, 1.5),
transpars> theta <<- phi + 2.0,
phi ~ dexp(1)
),
data = dat, chains = 4
)
alist(
A ~ dbetabinom(N, pbar, theta),
logit(pbar) <- a[gid],
a[gid] <- dnorm(0, 1.5),
transpars> theta <<- phi + 2.0,
phi ~ dexp(1)
)
?ulam
pbar <- 0.5
theta <- 5
curve(dbeta2(x,pbar,theta), from = 0, to = 1, xlab="Probability", ylab = "Density")
m12.1 <- ulam(
alist(
A ~ dbetabinom(N, pbar, theta),
logit(pbar) <- a[gid],
a[gid] <- dnorm(0, 1.5),
transpars> theta <<- phi + 2.0,
phi ~ dexp(1)
),
data = dat, chains = 4
)
data(UCBadmit)
d <- UCBadmit
library(rethinking)
data(UCBadmit)
library(rethinking)
data(UCBadmit)
d <- UCBadmit
d$gid <- ifelse( d$applicant.gender=="male" , 1L , 2L )
dat <- list( A=d$admit , N=d$applications , gid=d$gid )
m12.1 <- ulam(
alist(
A ~ dbetabinom( N , pbar , theta ),
logit(pbar) <- a[gid],
a[gid] ~ dnorm( 0 , 1.5 ),
transpars> theta <<- phi + 2.0,
phi ~ dexp(1)
), data=dat , chains=4 )
rebuild_cmdstan()
install.packages("rstan")
install.packages("cmdstanr")
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX14FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
example(stan_model, package = "rstan", run.dontrun = TRUE)
Sys.setenv(MAKEFLAGS = paste0("-j",parallel::detectCores()))
remove.packages("rstand")
remove.packages("rstan")
install.packages(c("StanHeaders","rstan"),type="source")
example(stan_model, package = "rstan", run.dontrun = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
R.version
R.version
installed.packages()
remotes::install_github("hartmast/concordances")
remotes::install_github("hartmast/wizard")
library(tidyverse)
library(MASS)
nettle <- read_csv("/Users/stefanhartmann/Library/CloudStorage/Dropbox/Privat/r_tests/bodobuch/applied_statistics_book_data-master/nettle_1999_climate.csv")
MGS_mdl <- glm(Langs ~ MGS, data = nettle, family = "Poisson")
MGS_mdl <- glm(Langs ~ MGS, data = nettle, family = "poisson")
tidy(MGS_mdl)
library(tidyverse)
?tidy
tidy(MGS_mdl)
library(MASS)
MGS_mdl
MGS_mdl %>% tidy
tidy
tidy()
library(broom)
tidy(MGS_mdl)
MGS_mdl <- glm(Langs ~ MGS + offset(Area), data = nettle, family = "poisson")
tidy(MGS_mdl)
mycoefs <- tidy(MGS_mdl)$estimate
intercept <- mycoefs[1]
slope <- mycoefs[2]
mycoefs
intercept + 0:12 * slope
exp(intercept + 0:12 * slope)
MGS_mdl <- glm.nb(Langs ~ MGS + offset(Area), data = nettle)
tidy(MGS_mdl)
summary(MGS_mdl)
library(effects)
install.packages("effects")
library(effects)
library(effects)
allEffects(MGS_mdl)
summary(MGS_mdl)
install.packages("foreign")
library(foreign)
dat <- read.dta("https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta")
dat <- within(dat, {
prog <- factor(prog, levels = 1:3, labels = c("General", "Academic", "Vocational"))
id <- factor(id)
})
dat
?within
summary(dat)
ggplot(dat, aes(daysabs, fill = prog)) + geom_histogram(binwidth = 1) + facet_grid(prog ~
., margins = TRUE, scales = "free")
with(dat, tapply(daysabs, prog, function(x) {
sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))
summary(m1 <- glm.nb(daysabs ~ math + prog, data = dat))
install.packages("psc1")
library(pscl)
install.packages("pscl")
library(pscl)
odTest(m1)
summary(m1)
m2 <- update(m1, . ~ . - prog)
anova(m1, m2)
pchisq(2 * (logLik(m1) - logLik(m3)), df = 1, lower.tail = FALSE)
m3 <- glm(daysabs ~ math + prog, family = "poisson", data = dat)
pchisq(2 * (logLik(m1) - logLik(m3)), df = 1, lower.tail = FALSE)
(est <- cbind(Estimate = coef(m1), confint(m1)))
exp(est)
newdata1 <- data.frame(math = mean(dat$math), prog = factor(1:3, levels = 1:3,
labels = levels(dat$prog)))
newdata1$phat <- predict(m1, newdata1, type = "response")
newdata1
newdata2 <- within(newdata2, {
DaysAbsent <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
newdata2 <- data.frame(
math = rep(seq(from = min(dat$math), to = max(dat$math), length.out = 100), 3),
prog = factor(rep(1:3, each = 100), levels = 1:3, labels =
levels(dat$prog)))
newdata2 <- cbind(newdata2, predict(m1, newdata2, type = "link", se.fit=TRUE))
newdata2 <- within(newdata2, {
DaysAbsent <- exp(fit)
LL <- exp(fit - 1.96 * se.fit)
UL <- exp(fit + 1.96 * se.fit)
})
ggplot(newdata2, aes(math, DaysAbsent)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
geom_line(aes(colour = prog), size = 2) +
labs(x = "Math Score", y = "Predicted Days Absent")
ggplot(newdata2, aes(math, DaysAbsent)) +
geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
geom_line(aes(colour = prog), linewidth = 2) +
labs(x = "Math Score", y = "Predicted Days Absent")
dlls <- getLoadedDLLs()
paths <- vapply(dlls, `[[`, "path", FUN.VALUE = character(1))
invisible(lapply(paths, function(path) {
if (!file.exists(path))
return(FALSE)
output <- system(paste("otool -L", shQuote(path), "| grep libc++ || true"),
intern = TRUE)
if (length(output) == 0)
return(FALSE)
writeLines(paste0(path, ":"))
writeLines(output)
}))
paths
install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
example(stan_model, package = "rstan", run.dontrun = TRUE)
install.packages(c("remotes", "Rcpp", "RcppArmadillo")
)
install.packages("Rcpp")
library(Rcpp)
sourceCpp("/Users/stefanhartmann/Downloads/helloworld.cpp")
install.packages("RcppArmadillo")
sourceCpp("/Users/stefanhartmann/Downloads/helloworld.cpp")
Rcpp::sourceCpp('path/to/file/helloworld.cpp')
Rcpp::sourceCpp('/Users/stefanhartmann/Downloads/helloworld.cpp')
cmdstanr::install_cmdstan()
install.packages("cmdstandr")
install.packages("cmdstanr")
install.packages("cmdstanr")
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
?install_cmdstan
install_cmdstan()
install_cmdstan()
install_cmdstan(overwrite = TRUE)
check_cmdstan_toolchain()
cmdstan_version()
cmdstanr::rebuild_cmdstan()
system("touch foo.cpp && R CMD SHLIB foo.cpp")
cmdstanr::rebuild_cmdstan()
system("touch foo.cpp && R CMD SHLIB foo.cpp")
system("touch foo.cpp && R CMD SHLIB foo.cpp")
cmdstanr::rebuild_cmdstan()
cmdstanr::install_cmdstan()
cmdstanr::cmdstanr_example()
file.edit("~/.Renviron")
#include <Rcpp.h>
using namespace std;
Rcpp::cppFunction('int add(int x, int y, int z) {
int sum = x + y + z;
return sum;
}')
unlink("~/.R/Makevars")
unlink("~/.Renviron")
Rcpp::evalCpp("1+1")
Rcpp::Rcpp.package.skeleton("SOanswer", example_code = FALSE)
Rcpp::compileAttributes("SOanswer/")
?link
?unlink
Rcpp::evalCpp("1+1")
library(cmdstanr)
cmdstanr_example()
remove.packages("Rstan")
remove.packages("cmdstanr")
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
check_cmdstan_toolchain(fix = TRUE, quiet = TRUE)
library(posterior)
library(bayesplot)
install.packages("bayesplot")
library(bayesplot)
color_scheme_set("brightblue")
check_cmdstan_toolchain()
install_cmdstan(cores = 2)
cmdstan_path()
cmdstan_version()
file <- file.path(cmdstan_path(), "examples", "bernoulli", "bernoulli.stan")
mod <- cmdstan_model(file)
cmdstanr::install_cmdstan()
?cmdstanr::install_cmdstan()
?cmdstanr::install_cmdstan(overwrite = TRUE)
cmdstanr::rebuild_cmdstan()
Rcpp::sourceCpp("/Users/stefanhartmann/Downloads/helloworld.cpp")
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX14FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
remove.packages("rstan")
remotes::install_github("stan-dev/rstan", ref = "develop", subdir = "rstan/rstan")
remotes::install_github("stan-dev/rstan", subdir = "rstan/rstan")
install.packages("rstan")
library(rstan)
example(stan_model, package = "rstan", run.dontrun = TRUE)
file.edit("~/.Renviron")
8*35
23280+0.19*23280
7.6*5
14.40*2
109*3
49.9/1.5
341/6
3000/681.71
681.71*4
533*3
75+60
681.76*4
681.76*5
85+54+1+28+1+29+2+3+11
install.packages("pscl")
library(tidyverse)
library(DT)
library(readxl)
library(googlesheets4)
#tbl <- read_sheet("https://docs.google.com/spreadsheets/d/1M5ZaoYkOrl0PQf3JbWwEz9GYVEwyXPWISGmhIGPSUAQ/edit?usp=sharing", sheet = "Talks")
tbl <- read_xlsx("Talks.xlsx", sheet = "Talks")
setwd("~/")
setwd("~/sciebo/Projekte/ICLC16/githubpage")
#tbl <- read_sheet("https://docs.google.com/spreadsheets/d/1M5ZaoYkOrl0PQf3JbWwEz9GYVEwyXPWISGmhIGPSUAQ/edit?usp=sharing", sheet = "Talks")
tbl <- read_xlsx("Talks.xlsx", sheet = "Talks")
# tbl <- read_xlsx("by_author.xlsx")
# tbl$Decision %>% unique
tbl <- filter(tbl, Decision %in% c("talk", "talk (remote)", "talk (maybe remote)"))
tbl <- select(tbl, "Last_Name_first_author", Authors, Title, "scheduled_for", "scheduled_time", "scheduled_room", Link, `Theme session`)
tbl$Title <- paste0("<a href=\"", tbl$Link, "\">", tbl$Title, "</a>")
tbl
#tbl <- read_sheet("https://docs.google.com/spreadsheets/d/1M5ZaoYkOrl0PQf3JbWwEz9GYVEwyXPWISGmhIGPSUAQ/edit?usp=sharing", sheet = "Talks")
tbl <- read_xlsx("Talks.xlsx", sheet = "Talks")
tbl$Decision
tbl$Decision %>% unique
tbl %>% filter(Decision != "reject")
tbl %>% filter(Decision != "reject" & !is.na(Decision))
566+6
